{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'datetime.datetime' has no attribute 'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 222\u001b[0m\n\u001b[0;32m    218\u001b[0m         all_data \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m    220\u001b[0m     all_data\u001b[38;5;241m.\u001b[39mto_parquet(all_data_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_data.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 222\u001b[0m \u001b[43mrunfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[67], line 193\u001b[0m, in \u001b[0;36mrunfile\u001b[1;34m()\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Setup the XRR experiment.\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Create the save location for the data\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m date \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    194\u001b[0m beamtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/XRR/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m date \u001b[38;5;241m=\u001b[39m date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'datetime.datetime' has no attribute 'datetime'"
     ]
    }
   ],
   "source": [
    "\"\"\"Run File Generator.\"\"\"\n",
    "\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "DATA_PATH = (\n",
    "    Path(\"Washington State University (email.wsu.edu)\")\n",
    "    / \"Carbon Lab Research Group - Documents\"\n",
    "    / \"Synchrotron Logistics and Data\"\n",
    "    / \"ALS - Berkeley\"\n",
    "    / \"Data\"\n",
    "    / \"BL1101\"\n",
    ")\n",
    "\n",
    "def unique_filename(path: Path) -> Path:\n",
    "    \"\"\"Generate a unique filename.\"\"\"\n",
    "    i = 1\n",
    "    while path.exists():\n",
    "        path = path.with_name(f\"{path.stem}({i}){path.suffix}\")\n",
    "        i += 1\n",
    "    return path\n",
    "\n",
    "def load_config(config: str | Path) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Parse the config.yaml file.\"\"\"\n",
    "    with config.open(\"rb\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    df = pd.DataFrame(config[\"energy\"])\n",
    "    return df, config[\"config\"]\n",
    "\n",
    "\n",
    "def process_stitch(\n",
    "    theta_i, theta_f, hos, hes, energy, et, points_per_fringe, fringe_size\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Process a stitch.\"\"\"\n",
    "    # Use q space instead of theta space\n",
    "    q_i = np.sin(np.deg2rad(theta_i)) * 4 * np.pi / (12.4 / energy)\n",
    "    q_f = np.sin(np.deg2rad(theta_f)) * 4 * np.pi / (12.4 / energy)\n",
    "\n",
    "    n_points = int(np.ceil((q_f - q_i) / fringe_size) * points_per_fringe)\n",
    "\n",
    "    q = np.linspace(q_i, q_f, n_points)\n",
    "    theta = np.rad2deg(np.arcsin(q * (12.4 / energy) / (4 * np.pi)))\n",
    "    ccd = 2 * theta\n",
    "    hos = np.full_like(theta, hos)\n",
    "    hes = np.full_like(theta, hes)\n",
    "    et = np.full_like(theta, et)\n",
    "\n",
    "    return pd.DataFrame({\"theta\": theta, \"ccd\": ccd, \"hos\": hos, \"hes\": hes, \"et\": et})\n",
    "\n",
    "\n",
    "def process_energy(df_slice: pd.DataFrame, config: dict, energy: float) -> pd.DataFrame:\n",
    "    \"\"\"Generate a chunk for a single energy.\"\"\"\n",
    "    theta = df_slice.loc[\"theta\"]\n",
    "    hos = df_slice.loc[\"hos\"]\n",
    "    hes = df_slice.loc[\"hes\"]\n",
    "    et = df_slice.loc[\"et\"]\n",
    "\n",
    "    # This is parameterized by the number of points in a fringe\n",
    "    points_per_fringe = config[\"collection\"][\"density\"]\n",
    "    fringe_size = 2 * np.pi / config[\"collection\"][\"thickness\"]\n",
    "\n",
    "    theta_pairs = [(theta[i], theta[i + 1]) for i in range(len(theta) - 1)]\n",
    "    energy_df = []\n",
    "    for i, (t_i, t_f) in enumerate(theta_pairs):\n",
    "        stitch_df = process_stitch(\n",
    "            t_i, t_f, hos[i], hes[i], energy, et[i], points_per_fringe, fringe_size\n",
    "        )\n",
    "        stitch_df[\"x\"] = config[\"geometry\"][\"x\"] + i * 0.1\n",
    "        energy_df.append(stitch_df)\n",
    "\n",
    "    energy_df = pd.concat(energy_df)\n",
    "    energy_df[\"energy\"] = energy\n",
    "    return energy_df\n",
    "\n",
    "\n",
    "def generate_runfile(macro_folder=str | Path) -> None:\n",
    "    r\"\"\"\n",
    "    Generate a run file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    macro_folder : str | Path\n",
    "        Location of the macro folder\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Outputs a run file macro for the ALS beamline 11.0.1.2 at the Advanced Light Source.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> generate_runfile(\"sample1\", path_to_save)\n",
    "    File\n",
    "    >>> Sample X --> ... Sample Theta --> CCD Theta --> ... Beamline Energy -->\n",
    "    >>> 12.4     --> ... 0.0           --> 0.0         --> ... 250          --> .001\n",
    "    >>> 12.4     --> ... 0.0           --> 0.0         --> ... 250          --> .001\n",
    "    >>>   ⋮                ⋮                  ⋮                   ⋮                 ⋮\n",
    "    >>> 12.4     --> ... 70            --> 140         --> ... 319          --> 10\n",
    "\n",
    "    Columns\n",
    "    -------\n",
    "    Sample X : float\n",
    "        Sample X position\n",
    "\n",
    "    Sample Y : float\n",
    "        Sample Y position\n",
    "\n",
    "    Sample Z : float\n",
    "        Sample Z position\n",
    "\n",
    "    Sample Theta : float\n",
    "        Sample Theta position\n",
    "\n",
    "    CCD Theta : float\n",
    "        CCD Theta position\n",
    "\n",
    "    Higher Order Suppressor : float\n",
    "        Higher Order Suppressor position\n",
    "\n",
    "    Horizontal Exit Slit Size: float\n",
    "        Horizontal Exit Slit position\n",
    "\n",
    "    Beamline Energy : float\n",
    "        Beamline Energy\n",
    "\n",
    "    Exposure Time : float\n",
    "        Exposure Time - This column has no label in the run file\n",
    "    \"\"\"\n",
    "    df_stitches, config = load_config(Path.cwd() / \"config.yaml\")\n",
    "    save_path = Path(macro_folder) / f\"{config[\"name\"]}.txt\"\n",
    "    # Generate a new name if the file allready exists\n",
    "\n",
    "    df = []\n",
    "    for i, en in enumerate(df_stitches.columns):\n",
    "        energy_df = process_energy(df_stitches[en], config, float(en))\n",
    "        energy_df[\"y\"] = config[\"geometry\"][\"y\"] + i * 0.1\n",
    "        df.append(energy_df)\n",
    "\n",
    "    df = pd.concat(df)\n",
    "    df[\"z\"] = config[\"geometry\"][\"z\"]\n",
    "    display(df)\n",
    "    df = df.reindex(\n",
    "        columns=[\n",
    "            \"x\",\n",
    "            \"y\",\n",
    "            \"z\",\n",
    "            \"theta\",\n",
    "            \"ccd\",\n",
    "            \"hos\",\n",
    "            \"hes\",\n",
    "            \"energy\",\n",
    "            \"et\",\n",
    "        ]\n",
    "    )\n",
    "    if save_path.exists():\n",
    "        # Check if ther are changes in the file\n",
    "        save_path = unique_filename(save_path)\n",
    "\n",
    "    df.to_csv(\n",
    "        save_path,\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "        header=[\n",
    "            \"Sample X\",\n",
    "            \"Sample Y\",\n",
    "            \"Sample Z\",\n",
    "            \"Sample Theta\",\n",
    "            \"CCD Theta\",\n",
    "            \"Higher Order Suppressor\",\n",
    "            \"Horizontal Exit Slit Size\",\n",
    "            \"Beamline Energy\",\n",
    "            \"\",\n",
    "        ],\n",
    "    )\n",
    "    display(df)\n",
    "    return df, config[\"name\"]\n",
    "\n",
    "    # Construct the runfile\n",
    "\n",
    "\n",
    "def runfile():\n",
    "    \"\"\"Setup the XRR experiment.\"\"\"\n",
    "    # Create the save location for the data\n",
    "    date = datetime.datetime.now()\n",
    "    beamtime = f\"{date.strftime('%Y%b')}/XRR/\"\n",
    "    date = date.strftime(\"%Y %m %d\")\n",
    "\n",
    "    data_path = Path.home() / DATA_PATH\n",
    "    save_path = data_path / beamtime / \".macro\" / date\n",
    "    all_data_path = data_path / \"XRR\"\n",
    "\n",
    "    if not save_path.exists():\n",
    "        save_path.mkdir(parents=True)\n",
    "        print(f\"Created {save_path}\")\n",
    "\n",
    "    if not all_data_path.exists():\n",
    "        all_data_path.mkdir(parents=True)\n",
    "        print(f\"Created {all_data_path}\")\n",
    "\n",
    "    # Generate the runfile\n",
    "    df, name = generate_runfile(save_path)\n",
    "    df[\"name\"] = name\n",
    "    df[\"date-time\"] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    if (all_data_path / \"all_data.parqet\").exists():\n",
    "        all_data = pd.read_csv(all_data_path / \"all_data.parquet\")\n",
    "        all_data = pd.concat([all_data, df])\n",
    "    else:\n",
    "        all_data = df\n",
    "\n",
    "    all_data.to_parquet(all_data_path / \"all_data.parquet\", index=False)\n",
    "\n",
    "runfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyref",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
